import urllib
import re

from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 

stop_words = set(stopwords.words('english')) 
url = ["https://www.gutenberg.org/files/1112/1112.txt",'http://www.gutenberg.org/cache/epub/2264/pg2264.txt','http://www.gutenberg.org/cache/epub/1128/pg1128.txt']
url_id=[1,2,3]
decoded_line=['','','']

# can turn into function which can be mapped to list of Urls by removing the for loop
for i in range(0,len(url)):
    print(i)
    file = urllib.request.urlopen(url[i])

    for line in file:
        decoded_line[i] = decoded_line[i]+line.decode("utf-8")
        
    decoded_line[i]= " ".join([w for w in word_tokenize(re.sub("[  ]"," ", re.sub("[^a-zA-Z]"," ", decoded_line[i])).lower()) if not w in stop_words])

a = dict(zip(url, decoded_line))

#map function
def inverted_index(key,value):
    b={}
    for j in value.split(' '):
        if j in b:
            if key not in b[j]:
                b[j].append(key)
        else:
             b[j] = key
    return(b)

zz=[inverted_index(k,v) for k, v in a.items()]

#reduce
def mergeDict(dict1, dict2):
    ''' Merge dictionaries and keep values of common keys in list'''
    dict3 = {**dict1, **dict2}
    for key, value in dict3.items():
        if key in dict1 and key in dict2:

            if isinstance(value, list):
                dict3[key] = sorted(value+[dict1[key]])
            else: 
                dict3[key] = sorted([value, dict1[key]])
    return dict3
# Merge dictionaries and add values of common keys in a list
dict3 = mergeDict(zz[2],mergeDict(zz[0], zz[1]))
